{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c903045",
   "metadata": {},
   "source": [
    "# Gradient Boosting Machine (GBM) Regressor - Dự đoán Tuổi thọ Trung bình\n",
    "\n",
    "## Mục tiêu:\n",
    "- Xây dựng mô hình Gradient Boosting Regressor để dự đoán tuổi thọ trung bình\n",
    "- Sử dụng dữ liệu đã được tiền xử lý từ `data/processed/`\n",
    "- Tối ưu hóa siêu tham số bằng 5-Fold Cross-Validation\n",
    "- Đánh giá mô hình trên tập validation và test\n",
    "- Lưu mô hình đã huấn luyện và trực quan hóa kết quả\n",
    "\n",
    "## Giới thiệu\n",
    "Gradient Boosting Machine (GBM) là một thuật toán ensemble learning mạnh mẽ, xây dựng mô hình theo cách tuần tự (sequential) thay vì song song như Random Forest. Mỗi cây mới được xây dựng để sửa chữa lỗi của các cây trước đó.\n",
    "\n",
    "## Ưu điểm\n",
    "- Hiệu suất dự đoán rất cao, thường vượt trội Random Forest.\n",
    "- Xử lý tốt các mối quan hệ phi tuyến phức tạp.\n",
    "- Tự động thực hiện chọn lọc đặc trưng.\n",
    "\n",
    "## Nhược điểm\n",
    "- Dễ bị overfitting.\n",
    "- Thời gian huấn luyện lâu.\n",
    "- Nhạy cảm với siêu tham số.\n",
    "- Khó giải thích hơn các mô hình đơn giản.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c71f6f",
   "metadata": {},
   "source": [
    "## Bước 1 - Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thư viện cơ bản\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Thư viện sklearn cho mô hình và đánh giá\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Thư viện để lưu mô hình\n",
    "import joblib\n",
    "\n",
    "# Cài đặt\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Đã import thành công tất cả thư viện!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e9793c",
   "metadata": {},
   "source": [
    "## Bước 2 - Đọc dữ liệu đã tiền xử lý\n",
    "\n",
    "Đọc dữ liệu từ các file CSV đã được tiền xử lý và chia sẵn thành train/validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "val_df = pd.read_csv('../data/processed/val.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"THÔNG TIN DỮ LIỆU\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Kích thước tập Train:      {train_df.shape}\")\n",
    "print(f\"Kích thước tập Validation: {val_df.shape}\")\n",
    "print(f\"Kích thước tập Test:       {test_df.shape}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Hiển thị 5 dòng đầu của tập train\n",
    "print(\"\\n5 dòng đầu tiên của tập Train:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446c293",
   "metadata": {},
   "source": [
    "## Bước 3 - Chuẩn bị dữ liệu cho mô hình\n",
    "\n",
    "Tách biến mục tiêu (`life_expectancy`) khỏi các đặc trưng. Loại bỏ các cột không cần thiết như `country_name`, `country_code`, và `year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa các cột đặc trưng (loại bỏ cột không cần thiết)\n",
    "feature_cols = [col for col in train_df.columns \n",
    "                if col not in ['life_expectancy', 'country_name', 'country_code', 'year']]\n",
    "\n",
    "# Tách X và y cho từng tập\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['life_expectancy']\n",
    "\n",
    "X_val = val_df[feature_cols]\n",
    "y_val = val_df['life_expectancy']\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df['life_expectancy']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"THÔNG TIN CÁC TẬP DỮ LIỆU\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Số lượng đặc trưng: {len(feature_cols)}\")\n",
    "print(f\"\\nCác đặc trưng được sử dụng:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "print(f\"\\nKích thước X_train: {X_train.shape}\")\n",
    "print(f\"Kích thước y_train: {y_train.shape}\")\n",
    "print(f\"Kích thước X_val:   {X_val.shape}\")\n",
    "print(f\"Kích thước y_val:   {y_val.shape}\")\n",
    "print(f\"Kích thước X_test:  {X_test.shape}\")\n",
    "print(f\"Kích thước y_test:  {y_test.shape}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d6cc8",
   "metadata": {},
   "source": [
    "## Bước 4 - Xây dựng mô hình GBM cơ bản\n",
    "\n",
    "Trước tiên, xây dựng một mô hình Gradient Boosting cơ bản với tham số mặc định để làm baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo mô hình Gradient Boosting với tham số mặc định\n",
    "gbm_baseline = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "print(\"Đang huấn luyện mô hình baseline...\")\n",
    "gbm_baseline.fit(X_train, y_train)\n",
    "print(\"✓ Hoàn thành huấn luyện!\")\n",
    "\n",
    "# Dự đoán trên tập train và validation\n",
    "y_train_pred_baseline = gbm_baseline.predict(X_train)\n",
    "y_val_pred_baseline = gbm_baseline.predict(X_val)\n",
    "\n",
    "# Tính toán các metrics\n",
    "train_mae_baseline = mean_absolute_error(y_train, y_train_pred_baseline)\n",
    "train_rmse_baseline = np.sqrt(mean_squared_error(y_train, y_train_pred_baseline))\n",
    "train_r2_baseline = r2_score(y_train, y_train_pred_baseline)\n",
    "\n",
    "val_mae_baseline = mean_absolute_error(y_val, y_val_pred_baseline)\n",
    "val_rmse_baseline = np.sqrt(mean_squared_error(y_val, y_val_pred_baseline))\n",
    "val_r2_baseline = r2_score(y_val, y_val_pred_baseline)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KẾT QUẢ MÔ HÌNH BASELINE (tham số mặc định)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTập TRAIN:\")\n",
    "print(f\"  MAE:  {train_mae_baseline:.4f} năm\")\n",
    "print(f\"  RMSE: {train_rmse_baseline:.4f} năm\")\n",
    "print(f\"  R²:   {train_r2_baseline:.4f}\")\n",
    "\n",
    "print(f\"\\nTập VALIDATION:\")\n",
    "print(f\"  MAE:  {val_mae_baseline:.4f} năm\")\n",
    "print(f\"  RMSE: {val_rmse_baseline:.4f} năm\")\n",
    "print(f\"  R²:   {val_r2_baseline:.4f}\")\n",
    "\n",
    "print(f\"\\nSố lượng cây (estimators): {gbm_baseline.n_estimators}\")\n",
    "print(f\"Learning rate: {gbm_baseline.learning_rate}\")\n",
    "print(f\"Max depth: {gbm_baseline.max_depth}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Nhận xét về overfitting\n",
    "if train_r2_baseline - val_r2_baseline > 0.1:\n",
    "    print(\"\\n⚠️  Mô hình có dấu hiệu overfitting (R² train >> R² val)\")\n",
    "    print(\"→  Cần tối ưu hóa siêu tham số để giảm overfitting\")\n",
    "else:\n",
    "    print(\"\\n✓ Mô hình khá cân bằng, nhưng vẫn có thể cải thiện thêm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3454470",
   "metadata": {},
   "source": [
    "## Bước 5 - Tối ưu hóa siêu tham số với GridSearchCV\n",
    "\n",
    "Sử dụng GridSearchCV với 5-Fold Cross-Validation để tìm kiếm siêu tham số tối ưu cho mô hình Gradient Boosting.\n",
    "\n",
    "### Các siêu tham số cần tối ưu:\n",
    "- **n_estimators:** Số lượng cây (boosting stages)\n",
    "- **learning_rate:** Tốc độ học (shrinkage), kiểm soát đóng góp của mỗi cây\n",
    "- **max_depth:** Độ sâu tối đa của mỗi cây\n",
    "- **min_samples_split:** Số mẫu tối thiểu để chia một nút\n",
    "- **min_samples_leaf:** Số mẫu tối thiểu ở một nút lá\n",
    "- **subsample:** Tỷ lệ mẫu được sử dụng để huấn luyện mỗi cây (giúp giảm overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa không gian siêu tham số để tìm kiếm\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TÌM KIẾM SIÊU THAM SỐ TỐI ƯU\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Số lượng tổ hợp tham số: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "print(\"Phương pháp: GridSearchCV với 5-Fold Cross-Validation\")\n",
    "print(\"Metric đánh giá: Negative RMSE (neg_root_mean_squared_error)\")\n",
    "print(\"\\nĐang thực hiện tìm kiếm...\")\n",
    "print(\"⚠️  Lưu ý: Quá trình này có thể mất nhiều thời gian (15-45 phút)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Tạo KFold với 5 folds\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Tạo GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=kfold,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Thực hiện tìm kiếm\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✓ Hoàn thành tìm kiếm!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c85672f",
   "metadata": {},
   "source": [
    "## Bước 6 - Phân tích kết quả GridSearchCV\n",
    "\n",
    "Hiển thị siêu tham số tối ưu và đánh giá hiệu suất của mô hình tốt nhất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa446720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy mô hình tốt nhất và tham số tối ưu\n",
    "best_gbm = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_cv_score = -grid_search.best_score_  # Chuyển về dương (RMSE)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SIÊU THAM SỐ TỐI ƯU\")\n",
    "print(\"=\"*60)\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param:20s}: {value}\")\n",
    "\n",
    "print(f\"\\nRMSE Cross-Validation (5-fold): {best_cv_score:.4f} năm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Thông tin về mô hình tối ưu\n",
    "print(f\"\\nSố lượng cây (estimators): {best_gbm.n_estimators}\")\n",
    "print(f\"Learning rate: {best_gbm.learning_rate}\")\n",
    "print(f\"Max depth: {best_gbm.max_depth}\")\n",
    "print(f\"Subsample: {best_gbm.subsample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb0c09",
   "metadata": {},
   "source": [
    "## Bước 7 - Đánh giá mô hình tối ưu trên tập Validation\n",
    "\n",
    "Sử dụng mô hình đã tối ưu để dự đoán trên tập validation và tính toán các metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea3c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập train và validation\n",
    "print(\"Đang thực hiện dự đoán...\")\n",
    "y_train_pred = best_gbm.predict(X_train)\n",
    "y_val_pred = best_gbm.predict(X_val)\n",
    "\n",
    "# Tính toán các metrics cho tập train\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Tính toán các metrics cho tập validation\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KẾT QUẢ MÔ HÌNH TỐI ƯU\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTập TRAIN:\")\n",
    "print(f\"  MAE:  {train_mae:.4f} năm\")\n",
    "print(f\"  RMSE: {train_rmse:.4f} năm\")\n",
    "print(f\"  R²:   {train_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nTập VALIDATION:\")\n",
    "print(f\"  MAE:  {val_mae:.4f} năm\")\n",
    "print(f\"  RMSE: {val_rmse:.4f} năm\")\n",
    "print(f\"  R²:   {val_r2:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SO SÁNH VỚI BASELINE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Cải thiện RMSE trên validation: {val_rmse_baseline - val_rmse:.4f} năm\")\n",
    "print(f\"Cải thiện R² trên validation:   {val_r2 - val_r2_baseline:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504713c8",
   "metadata": {},
   "source": [
    "## Bước 8 - Phân tích Feature Importance\n",
    "\n",
    "Phân tích mức độ quan trọng của từng đặc trưng trong việc dự đoán tuổi thọ trung bình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a089b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy feature importance\n",
    "feature_importance = best_gbm.feature_importances_\n",
    "\n",
    "# Tạo DataFrame để sắp xếp\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ĐỘ QUAN TRỌNG CỦA CÁC ĐẶC TRƯNG (Feature Importance)\")\n",
    "print(\"=\"*60)\n",
    "for idx, row in importance_df.iterrows():\n",
    "    print(f\"{row['feature']:20s}: {row['importance']:.4f} {'█' * int(row['importance'] * 100)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Vẽ biểu đồ feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'], color='darkviolet', edgecolor='black')\n",
    "plt.xlabel('Độ quan trọng', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Đặc trưng', fontsize=12, fontweight='bold')\n",
    "plt.title('Feature Importance - Gradient Boosting Regressor', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Tạo thư mục nếu chưa có\n",
    "os.makedirs('../visualization/gbm', exist_ok=True)\n",
    "plt.savefig('../visualization/gbm/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Đã lưu biểu đồ feature importance tại: ../visualization/gbm/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e880fde1",
   "metadata": {},
   "source": [
    "## Bước 9 - Trực quan hóa kết quả dự đoán\n",
    "\n",
    "Vẽ biểu đồ so sánh giá trị thực tế và giá trị dự đoán trên tập validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b316a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo figure với 2 subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Scatter plot - Predicted vs Actual (Validation)\n",
    "axes[0].scatter(y_val, y_val_pred, alpha=0.5, color='darkviolet', edgecolor='black', linewidth=0.5)\n",
    "axes[0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2, label='Dự đoán hoàn hảo')\n",
    "axes[0].set_xlabel('Tuổi thọ thực tế (năm)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Tuổi thọ dự đoán (năm)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title(f'Dự đoán vs Thực tế (Validation)\\nR² = {val_r2:.4f}, RMSE = {val_rmse:.4f}', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Residual plot\n",
    "residuals = y_val - y_val_pred\n",
    "axes[1].scatter(y_val_pred, residuals, alpha=0.5, color='darkorange', edgecolor='black', linewidth=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Tuổi thọ dự đoán (năm)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Residuals (Thực tế - Dự đoán)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Biểu đồ Residuals (Validation)', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/gbm/predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Đã lưu biểu đồ dự đoán tại: ../visualization/gbm/predictions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a748b573",
   "metadata": {},
   "source": [
    "## Bước 10 - Phân tích Cross-Validation scores\n",
    "\n",
    "Trực quan hóa phân bố điểm số RMSE từ 5-Fold Cross-Validation để đánh giá độ ổn định của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e173bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy kết quả cross-validation từ GridSearchCV\n",
    "cv_results = grid_search.cv_results_\n",
    "best_index = grid_search.best_index_\n",
    "\n",
    "# Lấy scores của mô hình tốt nhất qua các folds\n",
    "best_cv_scores = []\n",
    "for i in range(5):  # 5 folds\n",
    "    fold_score = -cv_results[f'split{i}_test_score'][best_index]  # Chuyển về RMSE dương\n",
    "    best_cv_scores.append(fold_score)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KẾT QUẢ 5-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "for i, score in enumerate(best_cv_scores, 1):\n",
    "    print(f\"Fold {i}: RMSE = {score:.4f} năm\")\n",
    "\n",
    "print(f\"\\nTrung bình: {np.mean(best_cv_scores):.4f} năm\")\n",
    "print(f\"Độ lệch chuẩn: {np.std(best_cv_scores):.4f} năm\")\n",
    "print(f\"Min: {np.min(best_cv_scores):.4f} năm\")\n",
    "print(f\"Max: {np.max(best_cv_scores):.4f} năm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), best_cv_scores, marker='o', linewidth=2, markersize=10, color='darkviolet')\n",
    "plt.axhline(y=np.mean(best_cv_scores), color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Trung bình = {np.mean(best_cv_scores):.4f}')\n",
    "plt.fill_between(range(1, 6), \n",
    "                 np.mean(best_cv_scores) - np.std(best_cv_scores),\n",
    "                 np.mean(best_cv_scores) + np.std(best_cv_scores),\n",
    "                 alpha=0.2, color='red', label=f'± 1 std = {np.std(best_cv_scores):.4f}')\n",
    "plt.xlabel('Fold', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('RMSE (năm)', fontsize=12, fontweight='bold')\n",
    "plt.title('RMSE qua các Folds trong Cross-Validation', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/gbm/cv_scores.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Đã lưu biểu đồ CV scores tại: ../visualization/gbm/cv_scores.png\")\n",
    "\n",
    "# Đánh giá độ ổn định\n",
    "if np.std(best_cv_scores) < 0.5:\n",
    "    print(\"\\n✓ Mô hình rất ổn định (độ lệch chuẩn < 0.5)\")\n",
    "elif np.std(best_cv_scores) < 1.0:\n",
    "    print(\"\\n✓ Mô hình khá ổn định (độ lệch chuẩn < 1.0)\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Mô hình có độ biến động cao (độ lệch chuẩn ≥ 1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48097f",
   "metadata": {},
   "source": [
    "## Bước 11 - Phân tích Training Deviance (Loss)\n",
    "\n",
    "Gradient Boosting cho phép theo dõi quá trình học qua từng iteration. Vẽ biểu đồ deviance (loss) để kiểm tra overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy train score qua các iterations\n",
    "train_score = best_gbm.train_score_\n",
    "\n",
    "# Tính validation score qua các iterations\n",
    "val_score = []\n",
    "for i, pred in enumerate(best_gbm.staged_predict(X_val)):\n",
    "    val_score.append(mean_squared_error(y_val, pred))\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(train_score) + 1), train_score, label='Training Loss', linewidth=2, color='blue')\n",
    "plt.plot(range(1, len(val_score) + 1), val_score, label='Validation Loss', linewidth=2, color='red')\n",
    "plt.xlabel('Số lượng Boosting Iterations', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Mean Squared Error (Loss)', fontsize=12, fontweight='bold')\n",
    "plt.title('Training vs Validation Loss qua các Iterations', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/gbm/training_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Đã lưu biểu đồ training loss tại: ../visualization/gbm/training_loss.png\")\n",
    "\n",
    "# Phân tích\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHÂN TÍCH TRAINING LOSS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training Loss (cuối): {train_score[-1]:.4f}\")\n",
    "print(f\"Validation Loss (cuối): {val_score[-1]:.4f}\")\n",
    "print(f\"Tổng số iterations: {len(train_score)}\")\n",
    "\n",
    "# Tìm iteration tốt nhất (validation loss thấp nhất)\n",
    "best_iteration = np.argmin(val_score) + 1\n",
    "print(f\"\\nIteration tốt nhất: {best_iteration}\")\n",
    "print(f\"Validation Loss tại iteration tốt nhất: {val_score[best_iteration-1]:.4f}\")\n",
    "\n",
    "if best_iteration < len(train_score) * 0.8:\n",
    "    print(\"\\n⚠️  Validation loss đạt tối thiểu sớm → Có thể giảm n_estimators\")\n",
    "else:\n",
    "    print(\"\\n✓ Validation loss cải thiện đến cuối → Số iterations phù hợp\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87093596",
   "metadata": {},
   "source": [
    "## Bước 12 - Đánh giá mô hình trên tập Test\n",
    "\n",
    "Đánh giá hiệu suất cuối cùng của mô hình trên tập test (dữ liệu chưa từng thấy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập test\n",
    "print(\"Đang dự đoán trên tập test...\")\n",
    "y_test_pred = best_gbm.predict(X_test)\n",
    "\n",
    "# Tính toán các metrics cho tập test\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KẾT QUẢ CUỐI CÙNG TRÊN TẬP TEST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMAE:  {test_mae:.4f} năm\")\n",
    "print(f\"RMSE: {test_rmse:.4f} năm\")\n",
    "print(f\"R²:   {test_r2:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Tạo bảng so sánh\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Tập dữ liệu': ['Train', 'Validation', 'Test'],\n",
    "    'MAE': [train_mae, val_mae, test_mae],\n",
    "    'RMSE': [train_rmse, val_rmse, test_rmse],\n",
    "    'R²': [train_r2, val_r2, test_r2]\n",
    "})\n",
    "\n",
    "print(\"\\nBẢNG SO SÁNH KẾT QUẢ:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Vẽ biểu đồ so sánh\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics = ['MAE', 'RMSE', 'R²']\n",
    "datasets = ['Train', 'Validation', 'Test']\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    values = comparison_df[metric].values\n",
    "    axes[idx].bar(datasets, values, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    axes[idx].set_ylabel(metric, fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_title(f'{metric} trên các tập dữ liệu', fontsize=13, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Thêm giá trị lên đầu cột\n",
    "    for i, v in enumerate(values):\n",
    "        axes[idx].text(i, v, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/gbm/comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Đã lưu biểu đồ so sánh tại: ../visualization/gbm/comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49074da",
   "metadata": {},
   "source": [
    "## Bước 13 - Lưu mô hình đã huấn luyện\n",
    "\n",
    "Lưu mô hình Gradient Boosting đã tối ưu vào file để sử dụng sau này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc3caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo thư mục saved_models/gbm nếu chưa có\n",
    "os.makedirs('../saved_models/gbm', exist_ok=True)\n",
    "\n",
    "# Lưu mô hình\n",
    "model_path = '../saved_models/gbm/gradient_boosting.pkl'\n",
    "joblib.dump(best_gbm, model_path)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LƯU MÔ HÌNH\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Đã lưu mô hình tại: {model_path}\")\n",
    "print(f\"Kích thước file: {os.path.getsize(model_path) / 1024:.2f} KB\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Kiểm tra tải lại mô hình\n",
    "loaded_model = joblib.load(model_path)\n",
    "y_test_pred_loaded = loaded_model.predict(X_test)\n",
    "test_rmse_loaded = np.sqrt(mean_squared_error(y_test, y_test_pred_loaded))\n",
    "\n",
    "print(f\"\\n✓ Kiểm tra tải lại mô hình:\")\n",
    "print(f\"  RMSE trên test (mô hình gốc):      {test_rmse:.4f} năm\")\n",
    "print(f\"  RMSE trên test (mô hình đã tải):   {test_rmse_loaded:.4f} năm\")\n",
    "print(f\"  Chênh lệch: {abs(test_rmse - test_rmse_loaded):.10f} (rất nhỏ → OK)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca8cbf",
   "metadata": {},
   "source": [
    "## Bước 14 - Phân tích sâu về Overfitting/Underfitting\n",
    "\n",
    "Phân tích learning curve để hiểu rõ hơn về hành vi của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aff2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Tính toán learning curve\n",
    "print(\"Đang tính toán learning curve (có thể mất vài phút)...\")\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    best_gbm, X_train, y_train,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Chuyển sang RMSE dương và tính mean, std\n",
    "train_scores_mean = -train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "val_scores_mean = -val_scores.mean(axis=1)\n",
    "val_scores_std = val_scores.std(axis=1)\n",
    "\n",
    "# Vẽ learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', linewidth=2, markersize=8, label='RMSE Train')\n",
    "plt.plot(train_sizes, val_scores_mean, 'o-', color='red', linewidth=2, markersize=8, label='RMSE Validation')\n",
    "\n",
    "plt.fill_between(train_sizes, \n",
    "                 train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std,\n",
    "                 alpha=0.2, color='blue')\n",
    "plt.fill_between(train_sizes,\n",
    "                 val_scores_mean - val_scores_std,\n",
    "                 val_scores_mean + val_scores_std,\n",
    "                 alpha=0.2, color='red')\n",
    "\n",
    "plt.xlabel('Số lượng mẫu huấn luyện', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('RMSE (năm)', fontsize=12, fontweight='bold')\n",
    "plt.title('Learning Curve - Gradient Boosting Regressor', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/gbm/learning_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Đã lưu learning curve tại: ../visualization/gbm/learning_curve.png\")\n",
    "\n",
    "# Phân tích\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHÂN TÍCH LEARNING CURVE\")\n",
    "print(\"=\"*60)\n",
    "gap = train_scores_mean[-1] - val_scores_mean[-1]\n",
    "if gap < 0.3:\n",
    "    print(\"✓ Khoảng cách giữa train và validation RMSE rất nhỏ\")\n",
    "    print(\"  → Mô hình cân bằng rất tốt\")\n",
    "elif gap < 0.5:\n",
    "    print(\"✓ Khoảng cách giữa train và validation RMSE nhỏ\")\n",
    "    print(\"  → Mô hình cân bằng tốt\")\n",
    "elif gap < 1.0:\n",
    "    print(\"⚠ Khoảng cách giữa train và validation RMSE trung bình\")\n",
    "    print(\"  → Có dấu hiệu overfitting nhẹ\")\n",
    "else:\n",
    "    print(\"✗ Khoảng cách giữa train và validation RMSE lớn\")\n",
    "    print(\"  → Mô hình bị overfitting, cần tăng regularization\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f34589",
   "metadata": {},
   "source": [
    "## Bước 15 - Phân tích ảnh hưởng của Learning Rate\n",
    "\n",
    "So sánh hiệu suất với các learning rate khác nhau để hiểu tác động của siêu tham số này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef730a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thử nghiệm với các learning rate khác nhau\n",
    "learning_rates = [0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "lr_results = []\n",
    "\n",
    "print(\"Đang thử nghiệm các learning rate khác nhau...\")\n",
    "for lr in learning_rates:\n",
    "    gbm_lr = GradientBoostingRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=lr,\n",
    "        max_depth=best_params['max_depth'],\n",
    "        random_state=42\n",
    "    )\n",
    "    gbm_lr.fit(X_train, y_train)\n",
    "    y_val_pred_lr = gbm_lr.predict(X_val)\n",
    "    val_rmse_lr = np.sqrt(mean_squared_error(y_val, y_val_pred_lr))\n",
    "    lr_results.append(val_rmse_lr)\n",
    "    print(f\"  Learning rate = {lr:.2f} → Validation RMSE = {val_rmse_lr:.4f}\")\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(learning_rates, lr_results, marker='o', linewidth=2, markersize=10, color='darkviolet')\n",
    "plt.axhline(y=val_rmse, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Best model RMSE = {val_rmse:.4f}')\n",
    "plt.xlabel('Learning Rate', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Validation RMSE (năm)', fontsize=12, fontweight='bold')\n",
    "plt.title('Ảnh hưởng của Learning Rate đến Hiệu suất', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/gbm/learning_rate_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Đã lưu biểu đồ learning rate analysis tại: ../visualization/gbm/learning_rate_analysis.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KẾT LUẬN VỀ LEARNING RATE\")\n",
    "print(\"=\"*60)\n",
    "print(\"Learning rate nhỏ (0.01-0.05):\")\n",
    "print(\"  - Học chậm nhưng ổn định\")\n",
    "print(\"  - Cần nhiều iterations hơn\")\n",
    "print(\"  - Ít bị overfitting\")\n",
    "print(\"\\nLearning rate trung bình (0.1-0.2):\")\n",
    "print(\"  - Cân bằng tốt giữa tốc độ và độ chính xác\")\n",
    "print(\"  - Thường cho kết quả tốt nhất\")\n",
    "print(\"\\nLearning rate lớn (>0.5):\")\n",
    "print(\"  - Học nhanh nhưng không ổn định\")\n",
    "print(\"  - Dễ bỏ lỡ optimal solution\")\n",
    "print(\"  - Có thể bị overfitting\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06f4c6",
   "metadata": {},
   "source": [
    "## Bước 16 - Tạo báo cáo tổng kết\n",
    "\n",
    "Tổng hợp tất cả thông tin quan trọng về mô hình vào một báo cáo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo báo cáo\n",
    "report = f\"\"\"\n",
    "{'='*70}\n",
    "           BÁO CÁO MÔ HÌNH GRADIENT BOOSTING REGRESSOR\n",
    "{'='*70}\n",
    "\n",
    "1. THÔNG TIN MÔ HÌNH:\n",
    "   - Loại mô hình: Gradient Boosting Regressor\n",
    "   - Thư viện: scikit-learn\n",
    "   - Thời gian tạo: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "2. SIÊU THAM SỐ TỐI ƯU:\n",
    "   - n_estimators: {best_params['n_estimators']}\n",
    "   - learning_rate: {best_params['learning_rate']}\n",
    "   - max_depth: {best_params['max_depth']}\n",
    "   - min_samples_split: {best_params['min_samples_split']}\n",
    "   - min_samples_leaf: {best_params['min_samples_leaf']}\n",
    "   - subsample: {best_params['subsample']}\n",
    "\n",
    "3. ĐẶC ĐIỂM MÔ HÌNH:\n",
    "   - Số lượng boosting stages: {best_gbm.n_estimators}\n",
    "   - Số đặc trưng: {len(feature_cols)}\n",
    "   - Iteration tốt nhất: {best_iteration}\n",
    "\n",
    "4. KẾT QUẢ ĐÁNH GIÁ:\n",
    "   \n",
    "   Tập TRAIN:\n",
    "   - MAE:  {train_mae:.4f} năm\n",
    "   - RMSE: {train_rmse:.4f} năm\n",
    "   - R²:   {train_r2:.4f}\n",
    "   \n",
    "   Tập VALIDATION:\n",
    "   - MAE:  {val_mae:.4f} năm\n",
    "   - RMSE: {val_rmse:.4f} năm\n",
    "   - R²:   {val_r2:.4f}\n",
    "   \n",
    "   Tập TEST (Final):\n",
    "   - MAE:  {test_mae:.4f} năm\n",
    "   - RMSE: {test_rmse:.4f} năm\n",
    "   - R²:   {test_r2:.4f}\n",
    "\n",
    "5. CROSS-VALIDATION (5-Fold):\n",
    "   - RMSE trung bình: {np.mean(best_cv_scores):.4f} năm\n",
    "   - Độ lệch chuẩn: {np.std(best_cv_scores):.4f} năm\n",
    "   - RMSE tối thiểu: {np.min(best_cv_scores):.4f} năm\n",
    "   - RMSE tối đa: {np.max(best_cv_scores):.4f} năm\n",
    "\n",
    "6. SO SÁNH VỚI BASELINE:\n",
    "   - Cải thiện RMSE validation: {val_rmse_baseline - val_rmse:.4f} năm\n",
    "   - Cải thiện R² validation: {val_r2 - val_r2_baseline:.4f}\n",
    "\n",
    "7. TOP 5 ĐẶC TRƯNG QUAN TRỌNG NHẤT:\n",
    "\"\"\"\n",
    "\n",
    "for i, (idx, row) in enumerate(importance_df.head(5).iterrows(), 1):\n",
    "    report += f\"   {i}. {row['feature']:20s}: {row['importance']:.4f}\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "8. TRAINING LOSS ANALYSIS:\n",
    "   - Training Loss (cuối): {train_score[-1]:.4f}\n",
    "   - Validation Loss (cuối): {val_score[-1]:.4f}\n",
    "   - Iteration tốt nhất: {best_iteration}/{len(train_score)}\n",
    "\n",
    "9. KẾT LUẬN:\n",
    "   - Mô hình Gradient Boosting đã được tối ưu hóa thành công\n",
    "   - Hiệu suất trên tập test: RMSE = {test_rmse:.4f} năm, R² = {test_r2:.4f}\n",
    "   - GBM thường cho hiệu suất cao hơn Random Forest nhờ học tuần tự\n",
    "   - Mô hình ổn định với độ lệch chuẩn CV: {np.std(best_cv_scores):.4f}\n",
    "   - Mô hình đã được lưu tại: {model_path}\n",
    "   - Các biểu đồ đã được lưu tại: ../visualization/gbm/\n",
    "\n",
    "10. ƯU ĐIỂM CỦA GRADIENT BOOSTING:\n",
    "   - Hiệu suất dự đoán rất cao, thường tốt nhất trong các thuật toán truyền thống\n",
    "   - Xử lý tốt mối quan hệ phi tuyến phức tạp\n",
    "   - Tự động feature selection thông qua feature importance\n",
    "   - Robust với outliers\n",
    "   - Có thể theo dõi quá trình học qua training loss\n",
    "\n",
    "11. NHƯỢC ĐIỂM VÀ LƯU Ý:\n",
    "   - Thời gian huấn luyện lâu hơn Random Forest (sequential)\n",
    "   - Dễ bị overfitting nếu không điều chỉnh cẩn thận\n",
    "   - Nhạy cảm với siêu tham số (đặc biệt learning_rate và n_estimators)\n",
    "   - Cần cân bằng giữa learning_rate và n_estimators\n",
    "\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Lưu báo cáo vào file\n",
    "report_path = '../saved_models/gbm/gradient_boosting_report.md'\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"\\n✓ Đã lưu báo cáo tại: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e980284",
   "metadata": {},
   "source": [
    "## Kết luận\n",
    "\n",
    "### Tổng kết:\n",
    "1. ✅ **Mô hình Gradient Boosting** đã được xây dựng và tối ưu hóa thành công\n",
    "2. ✅ **GridSearchCV với 5-Fold CV** đã tìm được bộ siêu tham số tối ưu\n",
    "3. ✅ **Feature Importance** đã xác định các yếu tố quan trọng nhất\n",
    "4. ✅ **Training Loss Analysis** giúp hiểu quá trình học của mô hình\n",
    "5. ✅ **Hiệu suất mô hình** đã được đánh giá toàn diện\n",
    "6. ✅ **Mô hình đã được lưu** tại `saved_models/gbm/gradient_boosting.pkl`\n",
    "7. ✅ **Trực quan hóa chi tiết** đã được tạo tại `visualization/gbm/`\n",
    "\n",
    "### Điểm nổi bật của Gradient Boosting:\n",
    "- **Sequential Learning:** Mỗi cây học từ lỗi của cây trước → Hiệu suất cao\n",
    "- **Gradient Descent:** Tối ưu hóa loss function một cách có hệ thống\n",
    "- **Learning Rate Control:** Kiểm soát tốc độ học giúp tránh overfitting\n",
    "- **Stage-wise Training:** Có thể dừng sớm khi validation loss không cải thiện\n",
    "\n",
    "### So sánh với các mô hình khác:\n",
    "| Đặc điểm | Decision Tree | Random Forest | Gradient Boosting |\n",
    "|----------|--------------|---------------|-------------------|\n",
    "| Cách xây dựng | Một cây đơn | Nhiều cây song song | Nhiều cây tuần tự |\n",
    "| Overfitting | Cao | Thấp | Trung bình |\n",
    "| Hiệu suất | Thấp | Cao | Rất cao |\n",
    "| Thời gian train | Nhanh | Trung bình | Chậm |\n",
    "| Giải thích | Dễ | Khó | Khó |\n",
    "\n",
    "### Khi nào nên dùng Gradient Boosting:\n",
    "✓ Khi cần hiệu suất dự đoán cao nhất  \n",
    "✓ Khi có đủ thời gian để tune hyperparameters  \n",
    "✓ Khi dữ liệu có mối quan hệ phức tạp  \n",
    "✓ Khi có kinh nghiệm xử lý overfitting  \n",
    "\n",
    "### Khi nào KHÔNG nên dùng:\n",
    "✗ Khi cần kết quả nhanh (thời gian train lâu)  \n",
    "✗ Khi cần giải thích chi tiết (black box)  \n",
    "✗ Khi dữ liệu quá nhỏ (dễ overfit)  \n",
    "✗ Khi không có thời gian tune parameters  \n",
    "\n",
    "### Bước tiếp theo:\n",
    "- So sánh với XGBoost (cải tiến của GBM)\n",
    "- So sánh với LightGBM và CatBoost\n",
    "- So sánh với SVM Regression\n",
    "- Xây dựng ensemble model kết hợp tất cả các thuật toán\n",
    "- Phân tích chi tiết các trường hợp dự đoán sai"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
