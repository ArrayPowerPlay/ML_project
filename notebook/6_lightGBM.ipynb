{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b57cf7",
   "metadata": {},
   "source": [
    "# LightGBM Regressor - Dá»± Ä‘oÃ¡n Tuá»•i thá» Trung bÃ¬nh\n",
    "\n",
    "## Má»¥c tiÃªu:\n",
    "- XÃ¢y dá»±ng mÃ´ hÃ¬nh LightGBM Regressor Ä‘á»ƒ dá»± Ä‘oÃ¡n tuá»•i thá» trung bÃ¬nh\n",
    "- Sá»­ dá»¥ng dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c tiá»n xá»­ lÃ½ tá»« `data/processed/`\n",
    "- Tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ báº±ng 5-Fold Cross-Validation\n",
    "- ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p validation vÃ  test\n",
    "- LÆ°u mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n vÃ  trá»±c quan hÃ³a káº¿t quáº£\n",
    "\n",
    "## Giá»›i thiá»‡u\n",
    "LightGBM (Light Gradient Boosting Machine) lÃ  má»™t framework gradient boosting Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Microsoft, tá»‘i Æ°u hÃ³a cho tá»‘c Ä‘á»™ vÃ  hiá»‡u suáº¥t cao. LightGBM sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t Ä‘á»™t phÃ¡ Ä‘á»ƒ cáº£i thiá»‡n tá»‘c Ä‘á»™ huáº¥n luyá»‡n vÃ  giáº£m sá»­ dá»¥ng bá»™ nhá»›.\n",
    "\n",
    "### **Æ¯u Ä‘iá»ƒm:**\n",
    "- Tá»‘c Ä‘á»™ huáº¥n luyá»‡n cá»±c nhanh (nhanh hÆ¡n XGBoost 10-20 láº§n)\n",
    "- Hiá»‡u suáº¥t cao, thÆ°á»ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c tá»‘t hÆ¡n XGBoost\n",
    "- Xá»­ lÃ½ tá»‘t dá»¯ liá»‡u lá»›n vÃ  nhiá»u chiá»u\n",
    "\n",
    "### **NhÆ°á»£c Ä‘iá»ƒm:**\n",
    "- Dá»… bá»‹ overfitting vá»›i dá»¯ liá»‡u nhá».\n",
    "- Nháº¡y cáº£m vá»›i siÃªu tham sá»‘.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf62ef",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 1 - Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1704106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThÆ° viá»‡n cÆ¡ báº£n\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ThÆ° viá»‡n LightGBM\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# ThÆ° viá»‡n sklearn cho Ä‘Ã¡nh giÃ¡\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ThÆ° viá»‡n Ä‘á»ƒ lÆ°u mÃ´ hÃ¬nh\n",
    "import joblib\n",
    "\n",
    "# CÃ i Ä‘áº·t\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ ÄÃ£ import thÃ nh cÃ´ng táº¥t cáº£ thÆ° viá»‡n!\")\n",
    "print(f\"LightGBM version: {lgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca209f60",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 2 - Äá»c dá»¯ liá»‡u Ä‘Ã£ tiá»n xá»­ lÃ½\n",
    "\n",
    "Äá»c dá»¯ liá»‡u tá»« cÃ¡c file CSV Ä‘Ã£ Ä‘Æ°á»£c tiá»n xá»­ lÃ½ vÃ  chia sáºµn thÃ nh train/validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678db5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Äá»c dá»¯ liá»‡u\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "val_df = pd.read_csv('../data/processed/val.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"THÃ”NG TIN Dá»® LIá»†U\")\n",
    "print(\"=\"*60)\n",
    "print(f\"KÃ­ch thÆ°á»›c táº­p Train:      {train_df.shape}\")\n",
    "print(f\"KÃ­ch thÆ°á»›c táº­p Validation: {val_df.shape}\")\n",
    "print(f\"KÃ­ch thÆ°á»›c táº­p Test:       {test_df.shape}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Hiá»ƒn thá»‹ 5 dÃ²ng Ä‘áº§u cá»§a táº­p train\n",
    "print(\"\\n5 dÃ²ng Ä‘áº§u tiÃªn cá»§a táº­p Train:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2a214b",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 3 - Chuáº©n bá»‹ dá»¯ liá»‡u cho mÃ´ hÃ¬nh\n",
    "\n",
    "TÃ¡ch biáº¿n má»¥c tiÃªu (`life_expectancy`) khá»i cÃ¡c Ä‘áº·c trÆ°ng. Loáº¡i bá» cÃ¡c cá»™t khÃ´ng cáº§n thiáº¿t nhÆ° `country_name`, `country_code`, vÃ  `year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c55b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Äá»‹nh nghÄ©a cÃ¡c cá»™t Ä‘áº·c trÆ°ng (loáº¡i bá» cá»™t khÃ´ng cáº§n thiáº¿t)\n",
    "feature_cols = [col for col in train_df.columns \n",
    "                if col not in ['life_expectancy', 'country_name', 'country_code', 'year']]\n",
    "\n",
    "# TÃ¡ch X vÃ  y cho tá»«ng táº­p\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['life_expectancy']\n",
    "\n",
    "X_val = val_df[feature_cols]\n",
    "y_val = val_df['life_expectancy']\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df['life_expectancy']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"THÃ”NG TIN CÃC Táº¬P Dá»® LIá»†U\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng: {len(feature_cols)}\")\n",
    "print(f\"\\nCÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c sá»­ dá»¥ng:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "print(f\"\\nKÃ­ch thÆ°á»›c X_train: {X_train.shape}\")\n",
    "print(f\"KÃ­ch thÆ°á»›c y_train: {y_train.shape}\")\n",
    "print(f\"KÃ­ch thÆ°á»›c X_val:   {X_val.shape}\")\n",
    "print(f\"KÃ­ch thÆ°á»›c y_val:   {y_val.shape}\")\n",
    "print(f\"KÃ­ch thÆ°á»›c X_test:  {X_test.shape}\")\n",
    "print(f\"KÃ­ch thÆ°á»›c y_test:  {y_test.shape}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625542c7",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 4 - XÃ¢y dá»±ng mÃ´ hÃ¬nh LightGBM cÆ¡ báº£n\n",
    "\n",
    "TrÆ°á»›c tiÃªn, xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh LightGBM cÆ¡ báº£n vá»›i tham sá»‘ máº·c Ä‘á»‹nh Ä‘á»ƒ lÃ m baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1583dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o mÃ´ hÃ¬nh LightGBM vá»›i tham sá»‘ máº·c Ä‘á»‹nh\n",
    "lgbm_baseline = LGBMRegressor(random_state=42, verbose=-1)\n",
    "\n",
    "# Huáº¥n luyá»‡n mÃ´ hÃ¬nh\n",
    "print(\"Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh baseline...\")\n",
    "lgbm_baseline.fit(X_train, y_train)\n",
    "print(\"âœ“ HoÃ n thÃ nh huáº¥n luyá»‡n!\")\n",
    "\n",
    "# Dá»± Ä‘oÃ¡n trÃªn táº­p train vÃ  validation\n",
    "y_train_pred_baseline = lgbm_baseline.predict(X_train)\n",
    "y_val_pred_baseline = lgbm_baseline.predict(X_val)\n",
    "\n",
    "# TÃ­nh toÃ¡n cÃ¡c metrics\n",
    "train_mae_baseline = mean_absolute_error(y_train, y_train_pred_baseline)\n",
    "train_rmse_baseline = np.sqrt(mean_squared_error(y_train, y_train_pred_baseline))\n",
    "train_r2_baseline = r2_score(y_train, y_train_pred_baseline)\n",
    "\n",
    "val_mae_baseline = mean_absolute_error(y_val, y_val_pred_baseline)\n",
    "val_rmse_baseline = np.sqrt(mean_squared_error(y_val, y_val_pred_baseline))\n",
    "val_r2_baseline = r2_score(y_val, y_val_pred_baseline)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Káº¾T QUáº¢ MÃ” HÃŒNH BASELINE (tham sá»‘ máº·c Ä‘á»‹nh)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTáº­p TRAIN:\")\n",
    "print(f\"  MAE:  {train_mae_baseline:.4f} nÄƒm\")\n",
    "print(f\"  RMSE: {train_rmse_baseline:.4f} nÄƒm\")\n",
    "print(f\"  RÂ²:   {train_r2_baseline:.4f}\")\n",
    "\n",
    "print(f\"\\nTáº­p VALIDATION:\")\n",
    "print(f\"  MAE:  {val_mae_baseline:.4f} nÄƒm\")\n",
    "print(f\"  RMSE: {val_rmse_baseline:.4f} nÄƒm\")\n",
    "print(f\"  RÂ²:   {val_r2_baseline:.4f}\")\n",
    "\n",
    "print(f\"\\nSá»‘ lÆ°á»£ng iterations: {lgbm_baseline.n_estimators}\")\n",
    "print(f\"Number of leaves: {lgbm_baseline.num_leaves}\")\n",
    "print(f\"Learning rate: {lgbm_baseline.learning_rate}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Nháº­n xÃ©t vá» overfitting\n",
    "if train_r2_baseline - val_r2_baseline > 0.1:\n",
    "    print(\"\\nâš ï¸  MÃ´ hÃ¬nh cÃ³ dáº¥u hiá»‡u overfitting (RÂ² train >> RÂ² val)\")\n",
    "    print(\"â†’  Cáº§n tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ Ä‘á»ƒ giáº£m overfitting\")\n",
    "else:\n",
    "    print(\"\\nâœ“ MÃ´ hÃ¬nh khÃ¡ cÃ¢n báº±ng, nhÆ°ng váº«n cÃ³ thá»ƒ cáº£i thiá»‡n thÃªm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e5660",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 5 - Tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ vá»›i GridSearchCV\n",
    "\n",
    "Sá»­ dá»¥ng GridSearchCV vá»›i 5-Fold Cross-Validation Ä‘á»ƒ tÃ¬m kiáº¿m siÃªu tham sá»‘ tá»‘i Æ°u cho mÃ´ hÃ¬nh LightGBM.\n",
    "\n",
    "### CÃ¡c siÃªu tham sá»‘ cáº§n tá»‘i Æ°u:\n",
    "- **num_leaves:** Sá»‘ lÆ°á»£ng lÃ¡ tá»‘i Ä‘a trong má»™t cÃ¢y (Ä‘iá»u khiá»ƒn Ä‘á»™ phá»©c táº¡p)\n",
    "- **max_depth:** Äá»™ sÃ¢u tá»‘i Ä‘a cá»§a cÃ¢y (giá»›i háº¡n overfitting)\n",
    "- **learning_rate:** Tá»‘c Ä‘á»™ há»c (shrinkage)\n",
    "- **n_estimators:** Sá»‘ lÆ°á»£ng boosting iterations\n",
    "- **min_child_samples:** Sá»‘ máº«u tá»‘i thiá»ƒu trong má»™t leaf (giá»‘ng min_samples_leaf)\n",
    "- **subsample:** Tá»· lá»‡ máº«u Ä‘Æ°á»£c sá»­ dá»¥ng (stochastic)\n",
    "- **colsample_bytree:** Tá»· lá»‡ features Ä‘Æ°á»£c sá»­ dá»¥ng cho má»—i cÃ¢y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f2a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Äá»‹nh nghÄ©a khÃ´ng gian siÃªu tham sá»‘ Ä‘á»ƒ tÃ¬m kiáº¿m\n",
    "param_grid = {\n",
    "    'num_leaves': [15, 31, 50, 70],\n",
    "    'max_depth': [5, 7, 10, 15, -1],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TÃŒM KIáº¾M SIÃŠU THAM Sá» Tá»I Æ¯U\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Sá»‘ lÆ°á»£ng tá»• há»£p tham sá»‘: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "print(\"PhÆ°Æ¡ng phÃ¡p: GridSearchCV vá»›i 5-Fold Cross-Validation\")\n",
    "print(\"Metric Ä‘Ã¡nh giÃ¡: Negative RMSE (neg_root_mean_squared_error)\")\n",
    "print(\"\\nÄang thá»±c hiá»‡n tÃ¬m kiáº¿m...\")\n",
    "print(\"âš ï¸  LÆ°u Ã½: QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t thá»i gian (10-30 phÃºt)\")\n",
    "print(\"          Tuy nhiÃªn, LightGBM nhanh hÆ¡n nhiá»u so vá»›i GBM truyá»n thá»‘ng!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Táº¡o KFold vá»›i 5 folds\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Táº¡o GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LGBMRegressor(random_state=42, verbose=-1),\n",
    "    param_grid=param_grid,\n",
    "    cv=kfold,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Thá»±c hiá»‡n tÃ¬m kiáº¿m\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nâœ“ HoÃ n thÃ nh tÃ¬m kiáº¿m!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31175db7",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 6 - PhÃ¢n tÃ­ch káº¿t quáº£ GridSearchCV\n",
    "\n",
    "Hiá»ƒn thá»‹ siÃªu tham sá»‘ tá»‘i Æ°u vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh tá»‘t nháº¥t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1256d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Láº¥y mÃ´ hÃ¬nh tá»‘t nháº¥t vÃ  tham sá»‘ tá»‘i Æ°u\n",
    "best_lgbm = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_cv_score = -grid_search.best_score_  # Chuyá»ƒn vá» dÆ°Æ¡ng (RMSE)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SIÃŠU THAM Sá» Tá»I Æ¯U\")\n",
    "print(\"=\"*60)\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param:20s}: {value}\")\n",
    "\n",
    "print(f\"\\nRMSE Cross-Validation (5-fold): {best_cv_score:.4f} nÄƒm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ThÃ´ng tin vá» mÃ´ hÃ¬nh tá»‘i Æ°u\n",
    "print(f\"\\nSá»‘ lÆ°á»£ng iterations: {best_lgbm.n_estimators}\")\n",
    "print(f\"Number of leaves: {best_lgbm.num_leaves}\")\n",
    "print(f\"Learning rate: {best_lgbm.learning_rate}\")\n",
    "print(f\"Max depth: {best_lgbm.max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7d8fc",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 7 - ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh tá»‘i Æ°u trÃªn táº­p Validation\n",
    "\n",
    "Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ tá»‘i Æ°u Ä‘á»ƒ dá»± Ä‘oÃ¡n trÃªn táº­p validation vÃ  tÃ­nh toÃ¡n cÃ¡c metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dá»± Ä‘oÃ¡n trÃªn táº­p train vÃ  validation\n",
    "print(\"Äang thá»±c hiá»‡n dá»± Ä‘oÃ¡n...\")\n",
    "y_train_pred = best_lgbm.predict(X_train)\n",
    "y_val_pred = best_lgbm.predict(X_val)\n",
    "\n",
    "# TÃ­nh toÃ¡n cÃ¡c metrics cho táº­p train\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# TÃ­nh toÃ¡n cÃ¡c metrics cho táº­p validation\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Káº¾T QUáº¢ MÃ” HÃŒNH Tá»I Æ¯U\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTáº­p TRAIN:\")\n",
    "print(f\"  MAE:  {train_mae:.4f} nÄƒm\")\n",
    "print(f\"  RMSE: {train_rmse:.4f} nÄƒm\")\n",
    "print(f\"  RÂ²:   {train_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nTáº­p VALIDATION:\")\n",
    "print(f\"  MAE:  {val_mae:.4f} nÄƒm\")\n",
    "print(f\"  RMSE: {val_rmse:.4f} nÄƒm\")\n",
    "print(f\"  RÂ²:   {val_r2:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SO SÃNH Vá»šI BASELINE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Cáº£i thiá»‡n RMSE trÃªn validation: {val_rmse_baseline - val_rmse:.4f} nÄƒm\")\n",
    "print(f\"Cáº£i thiá»‡n RÂ² trÃªn validation:   {val_r2 - val_r2_baseline:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8ef04",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 8 - PhÃ¢n tÃ­ch Feature Importance\n",
    "\n",
    "PhÃ¢n tÃ­ch má»©c Ä‘á»™ quan trá»ng cá»§a tá»«ng Ä‘áº·c trÆ°ng trong viá»‡c dá»± Ä‘oÃ¡n tuá»•i thá» trung bÃ¬nh. LightGBM cung cáº¥p 2 loáº¡i feature importance: split-based vÃ  gain-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e23e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Láº¥y feature importance (gain-based - máº·c Ä‘á»‹nh)\n",
    "feature_importance = best_lgbm.feature_importances_\n",
    "\n",
    "# Táº¡o DataFrame Ä‘á»ƒ sáº¯p xáº¿p\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Äá»˜ QUAN TRá»ŒNG Cá»¦A CÃC Äáº¶C TRÆ¯NG (Feature Importance)\")\n",
    "print(\"=\"*60)\n",
    "for idx, row in importance_df.iterrows():\n",
    "    print(f\"{row['feature']:20s}: {row['importance']:.4f} {'â–ˆ' * int(row['importance'] / max(importance_df['importance']) * 50)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Váº½ biá»ƒu Ä‘á»“ feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(importance_df)))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'], color=colors, edgecolor='black')\n",
    "plt.xlabel('Äá»™ quan trá»ng (Gain)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Äáº·c trÆ°ng', fontsize=12, fontweight='bold')\n",
    "plt.title('Feature Importance - LightGBM Regressor', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³\n",
    "os.makedirs('../visualization/lightgbm', exist_ok=True)\n",
    "plt.savefig('../visualization/lightgbm/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ feature importance táº¡i: ../visualization/lightgbm/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6e5342",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 9 - Trá»±c quan hÃ³a káº¿t quáº£ dá»± Ä‘oÃ¡n\n",
    "\n",
    "Váº½ biá»ƒu Ä‘á»“ so sÃ¡nh giÃ¡ trá»‹ thá»±c táº¿ vÃ  giÃ¡ trá»‹ dá»± Ä‘oÃ¡n trÃªn táº­p validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o figure vá»›i 2 subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Scatter plot - Predicted vs Actual (Validation)\n",
    "axes[0].scatter(y_val, y_val_pred, alpha=0.5, color='mediumseagreen', edgecolor='black', linewidth=0.5)\n",
    "axes[0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2, label='Dá»± Ä‘oÃ¡n hoÃ n háº£o')\n",
    "axes[0].set_xlabel('Tuá»•i thá» thá»±c táº¿ (nÄƒm)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Tuá»•i thá» dá»± Ä‘oÃ¡n (nÄƒm)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title(f'Dá»± Ä‘oÃ¡n vs Thá»±c táº¿ (Validation)\\nRÂ² = {val_r2:.4f}, RMSE = {val_rmse:.4f}', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Residual plot\n",
    "residuals = y_val - y_val_pred\n",
    "axes[1].scatter(y_val_pred, residuals, alpha=0.5, color='coral', edgecolor='black', linewidth=0.5)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Tuá»•i thá» dá»± Ä‘oÃ¡n (nÄƒm)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Residuals (Thá»±c táº¿ - Dá»± Ä‘oÃ¡n)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Biá»ƒu Ä‘á»“ Residuals (Validation)', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/lightgbm/predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ dá»± Ä‘oÃ¡n táº¡i: ../visualization/lightgbm/predictions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9f1e5",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 10 - PhÃ¢n tÃ­ch Cross-Validation scores\n",
    "\n",
    "Trá»±c quan hÃ³a phÃ¢n bá»‘ Ä‘iá»ƒm sá»‘ RMSE tá»« 5-Fold Cross-Validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ á»•n Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bbe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Láº¥y káº¿t quáº£ cross-validation tá»« GridSearchCV\n",
    "cv_results = grid_search.cv_results_\n",
    "best_index = grid_search.best_index_\n",
    "\n",
    "# Láº¥y scores cá»§a mÃ´ hÃ¬nh tá»‘t nháº¥t qua cÃ¡c folds\n",
    "best_cv_scores = []\n",
    "for i in range(5):  # 5 folds\n",
    "    fold_score = -cv_results[f'split{i}_test_score'][best_index]  # Chuyá»ƒn vá» RMSE dÆ°Æ¡ng\n",
    "    best_cv_scores.append(fold_score)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Káº¾T QUáº¢ 5-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "for i, score in enumerate(best_cv_scores, 1):\n",
    "    print(f\"Fold {i}: RMSE = {score:.4f} nÄƒm\")\n",
    "\n",
    "print(f\"\\nTrung bÃ¬nh: {np.mean(best_cv_scores):.4f} nÄƒm\")\n",
    "print(f\"Äá»™ lá»‡ch chuáº©n: {np.std(best_cv_scores):.4f} nÄƒm\")\n",
    "print(f\"Min: {np.min(best_cv_scores):.4f} nÄƒm\")\n",
    "print(f\"Max: {np.max(best_cv_scores):.4f} nÄƒm\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Váº½ biá»ƒu Ä‘á»“\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), best_cv_scores, marker='o', linewidth=2, markersize=10, color='mediumseagreen')\n",
    "plt.axhline(y=np.mean(best_cv_scores), color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Trung bÃ¬nh = {np.mean(best_cv_scores):.4f}')\n",
    "plt.fill_between(range(1, 6), \n",
    "                 np.mean(best_cv_scores) - np.std(best_cv_scores),\n",
    "                 np.mean(best_cv_scores) + np.std(best_cv_scores),\n",
    "                 alpha=0.2, color='red', label=f'Â± 1 std = {np.std(best_cv_scores):.4f}')\n",
    "plt.xlabel('Fold', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('RMSE (nÄƒm)', fontsize=12, fontweight='bold')\n",
    "plt.title('RMSE qua cÃ¡c Folds trong Cross-Validation', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/lightgbm/cv_scores.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ CV scores táº¡i: ../visualization/lightgbm/cv_scores.png\")\n",
    "\n",
    "# ÄÃ¡nh giÃ¡ Ä‘á»™ á»•n Ä‘á»‹nh\n",
    "if np.std(best_cv_scores) < 0.5:\n",
    "    print(\"\\nâœ“ MÃ´ hÃ¬nh ráº¥t á»•n Ä‘á»‹nh (Ä‘á»™ lá»‡ch chuáº©n < 0.5)\")\n",
    "elif np.std(best_cv_scores) < 1.0:\n",
    "    print(\"\\nâœ“ MÃ´ hÃ¬nh khÃ¡ á»•n Ä‘á»‹nh (Ä‘á»™ lá»‡ch chuáº©n < 1.0)\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  MÃ´ hÃ¬nh cÃ³ Ä‘á»™ biáº¿n Ä‘á»™ng cao (Ä‘á»™ lá»‡ch chuáº©n â‰¥ 1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d5d76",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 11 - PhÃ¢n tÃ­ch sá»‘ lÆ°á»£ng Leaves\n",
    "\n",
    "LightGBM sá»­ dá»¥ng leaf-wise tree growth. PhÃ¢n tÃ­ch sá»‘ lÆ°á»£ng leaves trong má»—i cÃ¢y Ä‘á»ƒ hiá»ƒu Ä‘á»™ phá»©c táº¡p cá»§a mÃ´ hÃ¬nh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Váº½ biá»ƒu Ä‘á»“ vá» num_leaves tá»‘i Æ°u\n",
    "print(\"=\"*60)\n",
    "print(\"PHÃ‚N TÃCH NUM_LEAVES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"num_leaves tá»‘i Æ°u: {best_lgbm.num_leaves}\")\n",
    "print(f\"max_depth tá»‘i Æ°u: {best_lgbm.max_depth}\")\n",
    "\n",
    "# TÃ­nh sá»‘ leaves tá»‘i Ä‘a cÃ³ thá»ƒ vá»›i max_depth\n",
    "if best_lgbm.max_depth > 0:\n",
    "    max_possible_leaves = 2 ** best_lgbm.max_depth\n",
    "    print(f\"Sá»‘ leaves tá»‘i Ä‘a cÃ³ thá»ƒ (vá»›i max_depth={best_lgbm.max_depth}): {max_possible_leaves}\")\n",
    "    print(f\"Tá»· lá»‡ sá»­ dá»¥ng: {best_lgbm.num_leaves / max_possible_leaves * 100:.1f}%\")\n",
    "else:\n",
    "    print(f\"max_depth = -1 (khÃ´ng giá»›i háº¡n)\")\n",
    "\n",
    "print(\"\\nğŸ’¡ LÆ¯U Ã:\")\n",
    "print(\"   - num_leaves > 2^max_depth cÃ³ thá»ƒ gÃ¢y overfitting\")\n",
    "print(\"   - num_leaves nhá» â†’ underfitting, mÃ´ hÃ¬nh quÃ¡ Ä‘Æ¡n giáº£n\")\n",
    "print(\"   - num_leaves lá»›n â†’ overfitting, mÃ´ hÃ¬nh quÃ¡ phá»©c táº¡p\")\n",
    "print(\"   - NÃªn giá»¯ num_leaves < 2^max_depth Ä‘á»ƒ trÃ¡nh overfitting\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# So sÃ¡nh hiá»‡u suáº¥t vá»›i cÃ¡c num_leaves khÃ¡c nhau\n",
    "num_leaves_values = [15, 31, 50, 70, 100]\n",
    "num_leaves_results = []\n",
    "\n",
    "print(\"\\nThá»­ nghiá»‡m vá»›i cÃ¡c num_leaves khÃ¡c nhau:\")\n",
    "for nl in num_leaves_values:\n",
    "    lgbm_nl = LGBMRegressor(\n",
    "        num_leaves=nl,\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    lgbm_nl.fit(X_train, y_train)\n",
    "    y_val_pred_nl = lgbm_nl.predict(X_val)\n",
    "    val_rmse_nl = np.sqrt(mean_squared_error(y_val, y_val_pred_nl))\n",
    "    num_leaves_results.append(val_rmse_nl)\n",
    "    print(f\"  num_leaves = {nl:3d} â†’ Validation RMSE = {val_rmse_nl:.4f}\")\n",
    "\n",
    "# Váº½ biá»ƒu Ä‘á»“\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(num_leaves_values, num_leaves_results, marker='o', linewidth=2, markersize=10, color='mediumseagreen')\n",
    "plt.axhline(y=val_rmse, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Best model RMSE = {val_rmse:.4f}')\n",
    "plt.axvline(x=best_lgbm.num_leaves, color='blue', linestyle='--', linewidth=2, alpha=0.5,\n",
    "            label=f'Best num_leaves = {best_lgbm.num_leaves}')\n",
    "plt.xlabel('Number of Leaves', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Validation RMSE (nÄƒm)', fontsize=12, fontweight='bold')\n",
    "plt.title('áº¢nh hÆ°á»Ÿng cá»§a Number of Leaves Ä‘áº¿n Hiá»‡u suáº¥t', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/lightgbm/num_leaves_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ num_leaves analysis táº¡i: ../visualization/lightgbm/num_leaves_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6cdbd0",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 12 - ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p Test\n",
    "\n",
    "ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t cuá»‘i cÃ¹ng cá»§a mÃ´ hÃ¬nh trÃªn táº­p test (dá»¯ liá»‡u chÆ°a tá»«ng tháº¥y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dá»± Ä‘oÃ¡n trÃªn táº­p test\n",
    "print(\"Äang dá»± Ä‘oÃ¡n trÃªn táº­p test...\")\n",
    "y_test_pred = best_lgbm.predict(X_test)\n",
    "\n",
    "# TÃ­nh toÃ¡n cÃ¡c metrics cho táº­p test\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Káº¾T QUáº¢ CUá»I CÃ™NG TRÃŠN Táº¬P TEST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMAE:  {test_mae:.4f} nÄƒm\")\n",
    "print(f\"RMSE: {test_rmse:.4f} nÄƒm\")\n",
    "print(f\"RÂ²:   {test_r2:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Táº¡o báº£ng so sÃ¡nh\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Táº­p dá»¯ liá»‡u': ['Train', 'Validation', 'Test'],\n",
    "    'MAE': [train_mae, val_mae, test_mae],\n",
    "    'RMSE': [train_rmse, val_rmse, test_rmse],\n",
    "    'RÂ²': [train_r2, val_r2, test_r2]\n",
    "})\n",
    "\n",
    "print(\"\\nBáº¢NG SO SÃNH Káº¾T QUáº¢:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Váº½ biá»ƒu Ä‘á»“ so sÃ¡nh\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics = ['MAE', 'RMSE', 'RÂ²']\n",
    "datasets = ['Train', 'Validation', 'Test']\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    values = comparison_df[metric].values\n",
    "    axes[idx].bar(datasets, values, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    axes[idx].set_ylabel(metric, fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_title(f'{metric} trÃªn cÃ¡c táº­p dá»¯ liá»‡u', fontsize=13, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # ThÃªm giÃ¡ trá»‹ lÃªn Ä‘áº§u cá»™t\n",
    "    for i, v in enumerate(values):\n",
    "        axes[idx].text(i, v, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/lightgbm/comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ so sÃ¡nh táº¡i: ../visualization/lightgbm/comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ad849",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 13 - LÆ°u mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n\n",
    "\n",
    "LÆ°u mÃ´ hÃ¬nh LightGBM Ä‘Ã£ tá»‘i Æ°u vÃ o file Ä‘á»ƒ sá»­ dá»¥ng sau nÃ y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bbfa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o thÆ° má»¥c saved_models/lightgbm náº¿u chÆ°a cÃ³\n",
    "os.makedirs('../saved_models/lightgbm', exist_ok=True)\n",
    "\n",
    "# LÆ°u mÃ´ hÃ¬nh\n",
    "model_path = '../saved_models/lightgbm/lightgbm.pkl'\n",
    "joblib.dump(best_lgbm, model_path)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LÆ¯U MÃ” HÃŒNH\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ ÄÃ£ lÆ°u mÃ´ hÃ¬nh táº¡i: {model_path}\")\n",
    "print(f\"KÃ­ch thÆ°á»›c file: {os.path.getsize(model_path) / 1024:.2f} KB\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Kiá»ƒm tra táº£i láº¡i mÃ´ hÃ¬nh\n",
    "loaded_model = joblib.load(model_path)\n",
    "y_test_pred_loaded = loaded_model.predict(X_test)\n",
    "test_rmse_loaded = np.sqrt(mean_squared_error(y_test, y_test_pred_loaded))\n",
    "\n",
    "print(f\"\\nâœ“ Kiá»ƒm tra táº£i láº¡i mÃ´ hÃ¬nh:\")\n",
    "print(f\"  RMSE trÃªn test (mÃ´ hÃ¬nh gá»‘c):      {test_rmse:.4f} nÄƒm\")\n",
    "print(f\"  RMSE trÃªn test (mÃ´ hÃ¬nh Ä‘Ã£ táº£i):   {test_rmse_loaded:.4f} nÄƒm\")\n",
    "print(f\"  ChÃªnh lá»‡ch: {abs(test_rmse - test_rmse_loaded):.10f} (ráº¥t nhá» â†’ OK)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b26a1c6",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 14 - PhÃ¢n tÃ­ch sÃ¢u vá» Overfitting/Underfitting\n",
    "\n",
    "PhÃ¢n tÃ­ch learning curve Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n vá» hÃ nh vi cá»§a mÃ´ hÃ¬nh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83637088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# TÃ­nh toÃ¡n learning curve\n",
    "print(\"Äang tÃ­nh toÃ¡n learning curve (cÃ³ thá»ƒ máº¥t vÃ i phÃºt)...\")\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    best_lgbm, X_train, y_train,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Chuyá»ƒn sang RMSE dÆ°Æ¡ng vÃ  tÃ­nh mean, std\n",
    "train_scores_mean = -train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "val_scores_mean = -val_scores.mean(axis=1)\n",
    "val_scores_std = val_scores.std(axis=1)\n",
    "\n",
    "# Váº½ learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color='blue', linewidth=2, markersize=8, label='RMSE Train')\n",
    "plt.plot(train_sizes, val_scores_mean, 'o-', color='red', linewidth=2, markersize=8, label='RMSE Validation')\n",
    "\n",
    "plt.fill_between(train_sizes, \n",
    "                 train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std,\n",
    "                 alpha=0.2, color='blue')\n",
    "plt.fill_between(train_sizes,\n",
    "                 val_scores_mean - val_scores_std,\n",
    "                 val_scores_mean + val_scores_std,\n",
    "                 alpha=0.2, color='red')\n",
    "\n",
    "plt.xlabel('Sá»‘ lÆ°á»£ng máº«u huáº¥n luyá»‡n', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('RMSE (nÄƒm)', fontsize=12, fontweight='bold')\n",
    "plt.title('Learning Curve - LightGBM Regressor', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/lightgbm/learning_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ ÄÃ£ lÆ°u learning curve táº¡i: ../visualization/lightgbm/learning_curve.png\")\n",
    "\n",
    "# PhÃ¢n tÃ­ch\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHÃ‚N TÃCH LEARNING CURVE\")\n",
    "print(\"=\"*60)\n",
    "gap = train_scores_mean[-1] - val_scores_mean[-1]\n",
    "if gap < 0.3:\n",
    "    print(\"âœ“ Khoáº£ng cÃ¡ch giá»¯a train vÃ  validation RMSE ráº¥t nhá»\")\n",
    "    print(\"  â†’ MÃ´ hÃ¬nh cÃ¢n báº±ng ráº¥t tá»‘t\")\n",
    "elif gap < 0.5:\n",
    "    print(\"âœ“ Khoáº£ng cÃ¡ch giá»¯a train vÃ  validation RMSE nhá»\")\n",
    "    print(\"  â†’ MÃ´ hÃ¬nh cÃ¢n báº±ng tá»‘t\")\n",
    "elif gap < 1.0:\n",
    "    print(\"âš  Khoáº£ng cÃ¡ch giá»¯a train vÃ  validation RMSE trung bÃ¬nh\")\n",
    "    print(\"  â†’ CÃ³ dáº¥u hiá»‡u overfitting nháº¹\")\n",
    "else:\n",
    "    print(\"âœ— Khoáº£ng cÃ¡ch giá»¯a train vÃ  validation RMSE lá»›n\")\n",
    "    print(\"  â†’ MÃ´ hÃ¬nh bá»‹ overfitting\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f665e9",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 15 - So sÃ¡nh tá»‘c Ä‘á»™ huáº¥n luyá»‡n\n",
    "\n",
    "So sÃ¡nh thá»i gian huáº¥n luyá»‡n cá»§a LightGBM vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c Ä‘á»ƒ tháº¥y Ä‘Æ°á»£c lá»£i tháº¿ vá» tá»‘c Ä‘á»™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# So sÃ¡nh tá»‘c Ä‘á»™ vá»›i cÃ¡c cáº¥u hÃ¬nh khÃ¡c nhau\n",
    "print(\"=\"*60)\n",
    "print(\"SO SÃNH Tá»C Äá»˜ HUáº¤N LUYá»†N\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "configs = [\n",
    "    {'n_estimators': 50, 'num_leaves': 31},\n",
    "    {'n_estimators': 100, 'num_leaves': 31},\n",
    "    {'n_estimators': 200, 'num_leaves': 31},\n",
    "    {'n_estimators': 100, 'num_leaves': 15},\n",
    "    {'n_estimators': 100, 'num_leaves': 70},\n",
    "]\n",
    "\n",
    "results = []\n",
    "for config in configs:\n",
    "    lgbm_speed = LGBMRegressor(\n",
    "        n_estimators=config['n_estimators'],\n",
    "        num_leaves=config['num_leaves'],\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    lgbm_speed.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    y_val_pred_speed = lgbm_speed.predict(X_val)\n",
    "    val_rmse_speed = np.sqrt(mean_squared_error(y_val, y_val_pred_speed))\n",
    "    \n",
    "    results.append({\n",
    "        'n_estimators': config['n_estimators'],\n",
    "        'num_leaves': config['num_leaves'],\n",
    "        'train_time': train_time,\n",
    "        'val_rmse': val_rmse_speed\n",
    "    })\n",
    "    \n",
    "    print(f\"n_estimators={config['n_estimators']:3d}, num_leaves={config['num_leaves']:2d} â†’ \"\n",
    "          f\"Time: {train_time:.3f}s, RMSE: {val_rmse_speed:.4f}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Váº½ biá»ƒu Ä‘á»“\n",
    "results_df = pd.DataFrame(results)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Thá»i gian huáº¥n luyá»‡n\n",
    "ax1.bar(range(len(results_df)), results_df['train_time'], color='skyblue', edgecolor='black')\n",
    "ax1.set_xlabel('Cáº¥u hÃ¬nh', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Thá»i gian (giÃ¢y)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Thá»i gian Huáº¥n luyá»‡n', fontsize=13, fontweight='bold')\n",
    "ax1.set_xticks(range(len(results_df)))\n",
    "ax1.set_xticklabels([f\"{r['n_estimators']}/{r['num_leaves']}\" for _, r in results_df.iterrows()], rotation=45)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# RMSE\n",
    "ax2.bar(range(len(results_df)), results_df['val_rmse'], color='lightcoral', edgecolor='black')\n",
    "ax2.set_xlabel('Cáº¥u hÃ¬nh', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Validation RMSE (nÄƒm)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Hiá»‡u suáº¥t Dá»± Ä‘oÃ¡n', fontsize=13, fontweight='bold')\n",
    "ax2.set_xticks(range(len(results_df)))\n",
    "ax2.set_xticklabels([f\"{r['n_estimators']}/{r['num_leaves']}\" for _, r in results_df.iterrows()], rotation=45)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualization/lightgbm/speed_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ speed comparison táº¡i: ../visualization/lightgbm/speed_comparison.png\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Káº¾T LUáº¬N:\")\n",
    "print(\"   - LightGBM cá»±c ká»³ nhanh, tháº­m chÃ­ vá»›i cáº¥u hÃ¬nh phá»©c táº¡p\")\n",
    "print(\"   - TÄƒng n_estimators â†’ tÄƒng thá»i gian tuyáº¿n tÃ­nh, cáº£i thiá»‡n accuracy\")\n",
    "print(\"   - TÄƒng num_leaves â†’ tÄƒng thá»i gian vÃ  accuracy, nhÆ°ng dá»… overfit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a062f",
   "metadata": {},
   "source": [
    "## BÆ°á»›c 16 - Táº¡o bÃ¡o cÃ¡o tá»•ng káº¿t\n",
    "\n",
    "Tá»•ng há»£p táº¥t cáº£ thÃ´ng tin quan trá»ng vá» mÃ´ hÃ¬nh vÃ o má»™t bÃ¡o cÃ¡o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o bÃ¡o cÃ¡o\n",
    "report = f\"\"\"\n",
    "{'='*70}\n",
    "              BÃO CÃO MÃ” HÃŒNH LIGHTGBM REGRESSOR\n",
    "{'='*70}\n",
    "\n",
    "1. THÃ”NG TIN MÃ” HÃŒNH:\n",
    "   - Loáº¡i mÃ´ hÃ¬nh: LightGBM Regressor\n",
    "   - ThÆ° viá»‡n: LightGBM (Microsoft)\n",
    "   - Version: {lgb.__version__}\n",
    "   - Thá»i gian táº¡o: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "2. SIÃŠU THAM Sá» Tá»I Æ¯U:\n",
    "   - num_leaves: {best_params['num_leaves']}\n",
    "   - max_depth: {best_params['max_depth']}\n",
    "   - learning_rate: {best_params['learning_rate']}\n",
    "   - n_estimators: {best_params['n_estimators']}\n",
    "   - min_child_samples: {best_params['min_child_samples']}\n",
    "   - subsample: {best_params['subsample']}\n",
    "   - colsample_bytree: {best_params['colsample_bytree']}\n",
    "\n",
    "3. Äáº¶C ÄIá»‚M MÃ” HÃŒNH:\n",
    "   - Tree growth strategy: Leaf-wise\n",
    "   - Sá»‘ lÆ°á»£ng iterations: {best_lgbm.n_estimators}\n",
    "   - Sá»‘ Ä‘áº·c trÆ°ng: {len(feature_cols)}\n",
    "\n",
    "4. Káº¾T QUáº¢ ÄÃNH GIÃ:\n",
    "   \n",
    "   Táº­p TRAIN:\n",
    "   - MAE:  {train_mae:.4f} nÄƒm\n",
    "   - RMSE: {train_rmse:.4f} nÄƒm\n",
    "   - RÂ²:   {train_r2:.4f}\n",
    "   \n",
    "   Táº­p VALIDATION:\n",
    "   - MAE:  {val_mae:.4f} nÄƒm\n",
    "   - RMSE: {val_rmse:.4f} nÄƒm\n",
    "   - RÂ²:   {val_r2:.4f}\n",
    "   \n",
    "   Táº­p TEST (Final):\n",
    "   - MAE:  {test_mae:.4f} nÄƒm\n",
    "   - RMSE: {test_rmse:.4f} nÄƒm\n",
    "   - RÂ²:   {test_r2:.4f}\n",
    "\n",
    "5. CROSS-VALIDATION (5-Fold):\n",
    "   - RMSE trung bÃ¬nh: {np.mean(best_cv_scores):.4f} nÄƒm\n",
    "   - Äá»™ lá»‡ch chuáº©n: {np.std(best_cv_scores):.4f} nÄƒm\n",
    "   - RMSE tá»‘i thiá»ƒu: {np.min(best_cv_scores):.4f} nÄƒm\n",
    "   - RMSE tá»‘i Ä‘a: {np.max(best_cv_scores):.4f} nÄƒm\n",
    "\n",
    "6. SO SÃNH Vá»šI BASELINE:\n",
    "   - Cáº£i thiá»‡n RMSE validation: {val_rmse_baseline - val_rmse:.4f} nÄƒm\n",
    "   - Cáº£i thiá»‡n RÂ² validation: {val_r2 - val_r2_baseline:.4f}\n",
    "\n",
    "7. TOP 5 Äáº¶C TRÆ¯NG QUAN TRá»ŒNG NHáº¤T:\n",
    "\"\"\"\n",
    "\n",
    "for i, (idx, row) in enumerate(importance_df.head(5).iterrows(), 1):\n",
    "    report += f\"   {i}. {row['feature']:20s}: {row['importance']:.4f}\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "8. Æ¯U ÄIá»‚M Cá»¦A LIGHTGBM:\n",
    "   - Tá»‘c Ä‘á»™ huáº¥n luyá»‡n cá»±c nhanh (nhanh hÆ¡n XGBoost 10-20 láº§n)\n",
    "   - Hiá»‡u suáº¥t cao, thÆ°á»ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c tá»‘t hÆ¡n XGBoost\n",
    "   - Sá»­ dá»¥ng bá»™ nhá»› hiá»‡u quáº£\n",
    "   - Leaf-wise tree growth cho accuracy cao hÆ¡n\n",
    "   - Há»— trá»£ categorical features trá»±c tiáº¿p\n",
    "   - Há»— trá»£ GPU training\n",
    "\n",
    "9. Ká»¸ THUáº¬T Äáº¶C BIá»†T:\n",
    "   - Gradient-based One-Side Sampling (GOSS)\n",
    "   - Exclusive Feature Bundling (EFB)\n",
    "   - Histogram-based algorithm\n",
    "   - Leaf-wise tree growth thay vÃ¬ level-wise\n",
    "\n",
    "10. Káº¾T LUáº¬N:\n",
    "   - MÃ´ hÃ¬nh LightGBM Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a thÃ nh cÃ´ng\n",
    "   - Hiá»‡u suáº¥t trÃªn táº­p test: RMSE = {test_rmse:.4f} nÄƒm, RÂ² = {test_r2:.4f}\n",
    "   - LightGBM lÃ  lá»±a chá»n tuyá»‡t vá»i cho dá»¯ liá»‡u lá»›n vÃ  cáº§n tá»‘c Ä‘á»™\n",
    "   - MÃ´ hÃ¬nh á»•n Ä‘á»‹nh vá»›i Ä‘á»™ lá»‡ch chuáº©n CV: {np.std(best_cv_scores):.4f}\n",
    "   - MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {model_path}\n",
    "   - CÃ¡c biá»ƒu Ä‘á»“ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: ../visualization/lightgbm/\n",
    "\n",
    "11. LÆ¯U Ã KHI Sá»¬ Dá»¤NG:\n",
    "   - num_leaves nÃªn < 2^max_depth Ä‘á»ƒ trÃ¡nh overfitting\n",
    "   - Dá»¯ liá»‡u nhá» (<1000 máº«u): cáº©n tháº­n vá»›i overfitting\n",
    "   - Learning rate nhá» + n_estimators lá»›n thÆ°á»ng cho káº¿t quáº£ tá»‘t\n",
    "   - Leaf-wise growth máº¡nh hÆ¡n nhÆ°ng dá»… overfit hÆ¡n level-wise\n",
    "\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# LÆ°u bÃ¡o cÃ¡o vÃ o file\n",
    "report_path = '../saved_models/lightgbm/lightgbm_report.md'\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"\\nâœ“ ÄÃ£ lÆ°u bÃ¡o cÃ¡o táº¡i: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d2db1",
   "metadata": {},
   "source": [
    "## Káº¿t luáº­n\n",
    "\n",
    "### Tá»•ng káº¿t:\n",
    "1. âœ… **MÃ´ hÃ¬nh LightGBM** Ä‘Ã£ Ä‘Æ°á»£c xÃ¢y dá»±ng vÃ  tá»‘i Æ°u hÃ³a thÃ nh cÃ´ng\n",
    "2. âœ… **GridSearchCV vá»›i 5-Fold CV** Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c bá»™ siÃªu tham sá»‘ tá»‘i Æ°u\n",
    "3. âœ… **Feature Importance** Ä‘Ã£ xÃ¡c Ä‘á»‹nh cÃ¡c yáº¿u tá»‘ quan trá»ng nháº¥t\n",
    "4. âœ… **Hiá»‡u suáº¥t cao** vá»›i tá»‘c Ä‘á»™ huáº¥n luyá»‡n cá»±c nhanh\n",
    "5. âœ… **MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u** táº¡i `saved_models/lightgbm/lightgbm.pkl`\n",
    "6. âœ… **Trá»±c quan hÃ³a chi tiáº¿t** Ä‘Ã£ Ä‘Æ°á»£c táº¡o táº¡i `visualization/lightgbm/`\n",
    "\n",
    "### Äiá»ƒm ná»•i báº­t cá»§a LightGBM:\n",
    "\n",
    "#### **1. Tá»‘c Ä‘á»™ VÆ°á»£t trá»™i**\n",
    "- Nhanh hÆ¡n GBM truyá»n thá»‘ng 10-100 láº§n\n",
    "- Nhanh hÆ¡n XGBoost 10-20 láº§n\n",
    "- PhÃ¹ há»£p cho dá»¯ liá»‡u lá»›n vÃ  production systems\n",
    "\n",
    "#### **2. Leaf-wise Tree Growth**\n",
    "- TÄƒng accuracy so vá»›i level-wise (GBM truyá»n thá»‘ng)\n",
    "- NhÆ°ng dá»… overfitting hÆ¡n vá»›i dá»¯ liá»‡u nhá»\n",
    "- Cáº§n Ä‘iá»u chá»‰nh num_leaves vÃ  max_depth cáº©n tháº­n\n",
    "\n",
    "#### **3. Ká»¹ thuáº­t Tá»‘i Æ°u**\n",
    "- **GOSS:** Giá»¯ gradient lá»›n, sample gradient nhá»\n",
    "- **EFB:** Gá»™p features sparse\n",
    "- **Histogram:** Binning thay vÃ¬ exact split\n",
    "\n",
    "### So sÃ¡nh vá»›i cÃ¡c thuáº­t toÃ¡n khÃ¡c:\n",
    "\n",
    "| Äáº·c Ä‘iá»ƒm | GBM | Random Forest | LightGBM |\n",
    "|----------|-----|---------------|----------|\n",
    "| Tá»‘c Ä‘á»™ | Cháº­m | Trung bÃ¬nh | Cá»±c nhanh |\n",
    "| Accuracy | Cao | Cao | Ráº¥t cao |\n",
    "| Overfitting | Trung bÃ¬nh | Tháº¥p | Cao (vá»›i dá»¯ liá»‡u nhá») |\n",
    "| Bá»™ nhá»› | Trung bÃ¬nh | Cao | Tháº¥p |\n",
    "| Tree growth | Level-wise | Parallel | Leaf-wise |\n",
    "\n",
    "### Khi nÃ o nÃªn dÃ¹ng LightGBM:\n",
    "\n",
    "âœ… **NÃŠN DÃ™NG:**\n",
    "- Dá»¯ liá»‡u lá»›n (>10,000 máº«u)\n",
    "- Cáº§n tá»‘c Ä‘á»™ huáº¥n luyá»‡n nhanh\n",
    "- Cáº§n hiá»‡u suáº¥t dá»± Ä‘oÃ¡n cao nháº¥t\n",
    "- CÃ³ nhiá»u features\n",
    "- Production systems cáº§n inference nhanh\n",
    "\n",
    "âŒ **KHÃ”NG NÃŠN DÃ™NG:**\n",
    "- Dá»¯ liá»‡u quÃ¡ nhá» (<1000 máº«u) â†’ dá»… overfit\n",
    "- Cáº§n giáº£i thÃ­ch chi tiáº¿t tá»«ng quyáº¿t Ä‘á»‹nh\n",
    "- KhÃ´ng cÃ³ thá»i gian tune hyperparameters\n",
    "- MÃ´i trÆ°á»ng bá»‹ giá»›i háº¡n bá»™ nhá»› ráº¥t nghiÃªm ngáº·t\n",
    "\n",
    "### Tips Ä‘á»ƒ trÃ¡nh Overfitting:\n",
    "\n",
    "1. **Giáº£m num_leaves**: Báº¯t Ä‘áº§u vá»›i 31, giáº£m xuá»‘ng náº¿u overfit\n",
    "2. **TÄƒng min_child_samples**: TÄƒng tá»« 20 lÃªn 50-100\n",
    "3. **Giáº£m max_depth**: Giá»›i háº¡n Ä‘á»™ sÃ¢u cÃ¢y\n",
    "4. **TÄƒng regularization**: Sá»­ dá»¥ng `reg_alpha`, `reg_lambda`\n",
    "5. **Subsample & colsample**: DÃ¹ng 0.7-0.9 thay vÃ¬ 1.0\n",
    "6. **Learning rate nhá»**: 0.01-0.05 vá»›i nhiá»u iterations\n",
    "\n",
    "### BÆ°á»›c tiáº¿p theo:\n",
    "- So sÃ¡nh chi tiáº¿t vá»›i XGBoost\n",
    "- Thá»­ nghiá»‡m vá»›i CatBoost\n",
    "- XÃ¢y dá»±ng ensemble model káº¿t há»£p táº¥t cáº£ boosting algorithms\n",
    "- Fine-tuning thÃªm vá»›i Bayesian Optimization\n",
    "- Deployment vÃ o production vá»›i ONNX hoáº·c serving frameworks"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
